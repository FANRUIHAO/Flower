首先找数据集:训练集、验证集、测试集（用于测试模型的泛化能力）
    包含有标签和无标签的
        对于无标签的要使用半监督学习
然后设置路径，设置函数用于读取路径下的数据 对数据进行处理（利用梯度下降算法）
    通过索引取数据的优势：可以实现随机抽像，可以打破数据的顺序性，防止模型过拟合
    注：什么是过拟合：是指模型在训练数据上表现得非常好，但在新数据上的表现差。
                  这是因为模型在训练过程中学到了数据中的噪声、细节，甚至是一些不重要的模式，而不是提取出数据的真正规律。
        解决方法：用正则化来缓解过拟合
设置图片大小：244*244*3  利于后续将图片转为向量 

    ps:图片分类方法：one-hot独热编码，不同的元素代表不同的类别，
        关键：卷积神经网络：对应矩阵的卷积操作得到特征图，然后将特整体变为矩阵
            因为卷积之后的矩阵会变小，如果想要保持图片尺寸不变：
            需要填充0(即使用ZeroPadding)ZeroPadding1卷一层即添加两列，ZaroPadding2卷两层即添加四列
        卷积操作后，通常会使用激活函数（如 ReLU）引入非线性，增强模型的表达能力
        一般不使用线性探测，因为其完全相信“大脑”，要进行微调，对大脑有所怀疑
卷积核大小不变，但是厚度会变
卷积核参数量就是卷积核大小平方乘以厚度

如果引入维度，就是引入卷积核
一个卷积核就可以卷出来一张特征图

#卷积神经网络计算：
特征图大小为卷积核卷出来的个数
卷积核的参数量即卷积核大小*厚度*卷积核数量
    244*244是因为这是vgg16的输入尺寸
    3是因为图片是彩色的（rgb三通道）
对数据集进行微调 变换：
* 图片增广：随机旋转，随机裁剪，随机水平翻转，随机垂直翻转，随机改变亮度，随机改变对比度，随机改变饱和度，随机改变色相，随机转换为灰度图
注意：1.nn.Linear  在中间多算几次，可以加深网络加强效果
  作用：随意转换矩阵的维度
* 
* 最后把图片转化为tensor，然后正则化

设置模型函数：用来定义模型（使用resnet18模型）
    使用resnet模型的好处：
        解决模型越深效果越差的问题
        ·梯度消失 & 梯度爆炸
        1)残差块
        2)残差网络
        3)残差网络的变种
    1、定义模型
    2、定义损失函数
    3、定义优化器
    4、定义学习率调度器
    5、定义训练函数
    6、定义测试函数
    7、定义训练过程函数
    8、定义测试过程函数
    9、定义训练和测试的主函数

    用torch来帮助自动计算loss,起到优化模型的目的
    如何做到的？
    answer：一个深度模型是在做什么？
        拥有一批x和y，通过模型预测到一个好的y
        再通过真实的y和预测的y，计算出差距也就是loss
        然后通过这个差距去改变优化模型，得到更好的模型，让模型更好的预测y
        不断多轮次的训练去预测更加准确的y


设置综合训练集和验证集对模型进行训练和验证的函数
    将模型放到设备上（cpu或gpu）
    # 记录训练和验证的损失和准确率
    设置迭代次数
        开始训练和验证
        训练阶段：
            将数据移动到设备上，梯度清零，向前传播，计算损失，反向传播，更新参数
            累加损失，计算准确率，计算平均训练损失和准确率
            进行验证 计算val_loss
            注意：
                验证集只能验证模型，不能训练模型，也就是说验证模型的梯度不能积攒到模型中
            保存最佳模型
        画出训练和验证的损失和准确率曲线

设置超参数
    设置学习率lr
    设置批次大小batchsize
    设置优化器：使用adamW优化器，比sgd和adam更好
            Adam 更稳定 效果更好，很难出现梯度爆炸
    设置迭代次数epoch
    设置训练集和验证集的路径
    设置模型保存路径
    设置模型加载路径

# 实例化训练和验证

训练好的模型的loss和accuracy的曲线：



ps：主成分分析法PCA：作用为进行降维
